{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18nn1wO8s-bL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08fcac8-ff93-46a6-caaf-fe1b131b7d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.8-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.9.0 pytorch-lightning-2.0.8 torchmetrics-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Gkf0xC3p-t",
        "outputId": "a6761e57-e900-414a-b10a-a8ccf863455d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7UNBIsqtJqT"
      },
      "outputs": [],
      "source": [
        "# Imports go here -- a bit shabby for now...\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import urllib.request\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import zipfile\n",
        "import pickle\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertForMaskedLM, BertModel, get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoX4-gjHHTOF"
      },
      "outputs": [],
      "source": [
        "def free_memory():\n",
        "  with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPv91brIx9E3"
      },
      "outputs": [],
      "source": [
        "# Some flags for the rest of the notebook\n",
        "force_download = False\n",
        "process_dictionaries=True\n",
        "filter_using_glove = True\n",
        "dont_use_edmt = True\n",
        "dont_use_webster = True\n",
        "dont_use_unix = False\n",
        "use_lstm_model = True\n",
        "use_multi_layers = False\n",
        "force_restart_training = False\n",
        "NUM_TARGET_EPOCHS = 50          # Used for linear schedule\n",
        "if use_multi_layers:\n",
        "  if dont_use_unix:\n",
        "    CHECKPT_DIR = \"/content/drive/MyDrive/iisc/reverse_dictionary/checkpoint/rd-checkpt-bl-2\"\n",
        "  else:\n",
        "    CHECKPT_DIR = \"/content/drive/MyDrive/iisc/reverse_dictionary/checkpoint/rd-checkpt-bl-4\"\n",
        "else:\n",
        "  if dont_use_unix:\n",
        "    CHECKPT_DIR = \"/content/drive/MyDrive/iisc/reverse_dictionary/checkpoint/rd-checkpt-bl-1\"\n",
        "  else:\n",
        "    CHECKPT_DIR = \"/content/drive/MyDrive/iisc/reverse_dictionary/checkpoint/rd-checkpt-bl-3\"\n",
        "sample_bad_words = ['timewrn', 'svahng', 'bulletinyyy', 'seabream', 'srivalo', 'nortelnet', 'piyanart', 'prohertrib', 'canyonres']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNh-N5SmwbBP",
        "outputId": "c5f710b0-8e2e-4d9e-d577-8bfbc984136e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "if force_download or not os.path.isfile('/content/drive/MyDrive/iisc/reverse_dictionary/data/webster_dict.json'):\n",
        "  urllib.request.urlretrieve (\"https://raw.githubusercontent.com/matthewreagan/WebstersEnglishDictionary/master/dictionary.json\", \"/content/drive/MyDrive/iisc/reverse_dictionary/data/webster_dict.json\")\n",
        "if force_download or not os.path.isfile('/content/drive/MyDrive/iisc/reverse_dictionary/data/edmt_dict.json'):\n",
        "  urllib.request.urlretrieve (\"https://raw.githubusercontent.com/eddydn/DictionaryDatabase/master/EDMTDictionary.json\", \"/content/drive/MyDrive/iisc/reverse_dictionary/data/edmt_dict.json\")\n",
        "nltk.download('wordnet')\n",
        "wordnet = [(synset.lemma_names()[0], synset.definition()) for synset in wn.all_synsets()]\n",
        "wordnet = [(word, defn) for (word, defn) in wordnet if '_' not in word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcsTW3vJhFfy"
      },
      "outputs": [],
      "source": [
        "if force_download or not os.path.isfile('/content/drive/MyDrive/iisc/reverse_dictionary/data/glove_6B_100d.pkl'):\n",
        "  urllib.request.urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \"glove.6B.zip\")\n",
        "  with zipfile.ZipFile(\"glove.6B.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "  print('Indexing word vectors.')\n",
        "  embeddings_index = {}\n",
        "  f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "\n",
        "  print('Found %s word vectors.' % len(embeddings_index))\n",
        "  pickle.dump({'embeddings_index' : embeddings_index } , open('/content/drive/MyDrive/iisc/reverse_dictionary/data/glove_6B_100d.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "zNqz10wDkmBm",
        "outputId": "0da82c61-8384-4d2e-9eac-eb0126afdbd7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-654ebf1c2a33>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/iisc/reverse_dictionary/data/glove_6B_100d.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embeddings_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example glove vector for 'sprint': \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sprint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
          ]
        }
      ],
      "source": [
        "glove_vectors = pickle.load(open('/content/drive/MyDrive/iisc/reverse_dictionary/data/glove_6B_100d.pkl', 'rb'))['embeddings_index']\n",
        "print(\"Example glove vector for 'sprint': \", glove_vectors['sprint'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Define the GloVe URL and file name\n",
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_filename = \"glove.6B.zip\"\n",
        "\n",
        "# Define the directory where you want to save the downloaded files\n",
        "download_dir = \"/content/drive/MyDrive/iisc/reverse_dictionary/data\"\n",
        "\n",
        "# Check if the file already exists, and if not, download it\n",
        "if not os.path.isfile(os.path.join(download_dir, glove_filename)):\n",
        "    print(\"Downloading GloVe vectors...\")\n",
        "    urllib.request.urlretrieve(glove_url, os.path.join(download_dir, glove_filename))\n",
        "    print(\"Download completed.\")\n",
        "\n",
        "\n",
        "print(\"GloVe vectors have been downloaded and extracted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWN7gj5-_vS6",
        "outputId": "0285ca2a-2144-4f97-ae7e-9a97880acd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe vectors have been downloaded and extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the downloaded zip file\n",
        "with zipfile.ZipFile(os.path.join(download_dir, glove_filename), 'r') as zip_ref:\n",
        "    zip_ref.extractall(download_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "d1yHvMNh-Vnr",
        "outputId": "2b0ce28f-8dff-44c0-d58f-bbe1a0b56300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9cfd39223dba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract the downloaded zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Specify the path to the GloVe text file (e.g., 100-dimensional vectors)\n",
        "glove_file_path = \"/content/drive/MyDrive/iisc/reverse_dictionary/data/glove.6B.100d.txt\"\n",
        "\n",
        "# Initialize an empty dictionary to store GloVe vectors\n",
        "glove_vectors = {}\n",
        "\n",
        "# Read the GloVe file and populate the dictionary\n",
        "with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_vectors[word] = vector\n",
        "\n",
        "print(f\"Loaded {len(glove_vectors)} word vectors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf8PHwM4A2Hh",
        "outputId": "92ef6af0-c381-417d-e39e-beab795eab45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gn0ufcgi-omE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple_vector = glove_vectors.get(\"apple\", None)\n",
        "if apple_vector is not None:\n",
        "    print(\"Vector for 'apple':\", apple_vector.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhjmGUcaCEpU",
        "outputId": "9552018d-8a4a-445a-eda0-f5765d6a385a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'apple': (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrAmDz8QzV7w"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"\n",
        "  Cleans the text. For now, a no-op\n",
        "  \"\"\"\n",
        "  return text\n",
        "\n",
        "def remove_duplicates(dictionary):\n",
        "  \"\"\"\n",
        "  The EDMT dictionary has duplicates, e.g. two definitions of 'A'.\n",
        "  Given a list of (word, meaning pairs), throws away all but the first definition for each word.\n",
        "  https://stackoverflow.com/questions/29563953/most-pythonic-way-to-remove-tuples-from-a-list-if-first-element-is-a-duplicate\n",
        "  \"\"\"\n",
        "  return list(OrderedDict(dictionary[::-1]).items())[::-1]\n",
        "\n",
        "def split_definitions_webster(combined, min_word_count=3):\n",
        "  \"\"\"\n",
        "  Split a string giving multiple definitions into its constitutents, and then filter by the minimum word count. Webster uses the convention -\n",
        "  1. First definition 2. Second definition 3. ...\n",
        "  \"\"\"\n",
        "  max_count = 0\n",
        "  last_index = -1\n",
        "  splits = [0]\n",
        "  while True:\n",
        "    search_for = \"{}.\".format(max_count+1)\n",
        "    found_index = combined.find(search_for)\n",
        "    if found_index <= last_index:\n",
        "      break\n",
        "    splits.append(found_index)\n",
        "    last_index = found_index\n",
        "    max_count += 1\n",
        "  if max_count <= 1:\n",
        "    defs = [combined.strip()]\n",
        "  else:\n",
        "    defs = [combined[i+2:j].strip() for i,j in zip(splits, splits[1:]+[None])]\n",
        "  return [defn for defn in defs if len(defn.split()) >= min_word_count]\n",
        "\n",
        "def split_definitions_edmt(combined, min_word_count=5):\n",
        "  \"\"\"\n",
        "  Split a string giving multiple definitions into its constitutents, and then filter by the minimum word count. EDMT uses the convention -\n",
        "  First definition ; Second definition ; ...\n",
        "  \"\"\"\n",
        "  if ';' in combined:\n",
        "    defs = [defn.strip() for defn in combined.split(';')]\n",
        "  else:\n",
        "    defs = [combined.strip()]\n",
        "  return [defn for defn in defs if len(defn.split()) >= min_word_count]\n",
        "\n",
        "def should_use_definition(word, definition, min_prefix_overlap=6, retain_probability = 0):\n",
        "  \"\"\"\n",
        "  Some definitions are just poor for training. Consider:\n",
        "  'The quality of being brutal' - brutalistic\n",
        "  There are a lot of examples like this among our training data -- we thus weed out those definitions where the word\n",
        "  shares a prefix of length >= min_prefix_overlap with a word in the definition.\n",
        "  We overlook a few cases with probability retain_probability\n",
        "  \"\"\"\n",
        "  min_prefix_overlap = min(min_prefix_overlap, len(word))\n",
        "  ok = True\n",
        "  for def_word in definition.split():\n",
        "    if len(def_word) < min_prefix_overlap:\n",
        "      continue\n",
        "    if def_word[:min_prefix_overlap].lower() == word[:min_prefix_overlap].lower():\n",
        "      ok = False\n",
        "      break\n",
        "  if ok:\n",
        "    return True\n",
        "  elif retain_probability > 0 and random.random() < retain_probability:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def process_dictionary(dictionary, name):\n",
        "  \"\"\"\n",
        "  Split definitions and filter them.\n",
        "  \"\"\"\n",
        "  processed = []\n",
        "  for word, defn in dictionary:\n",
        "    if name == 'webster':\n",
        "      defs = split_definitions_webster(defn)\n",
        "    elif name == 'edmt':\n",
        "      defs = split_definitions_edmt(defn)\n",
        "    else:\n",
        "      defs = [defn]\n",
        "    for split_defn in defs:\n",
        "      if should_use_definition(word, split_defn):\n",
        "        processed.append((word, split_defn))\n",
        "  return processed\n",
        "\n",
        "def glove_filter(dictionary):\n",
        "  \"\"\"\n",
        "  Throw out those entries where the word is not in glove\n",
        "  \"\"\"\n",
        "  dictionary = [(word, defn) for (word, defn) in dictionary if word in glove_vectors]\n",
        "  return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ARaE1jxnuP"
      },
      "outputs": [],
      "source": [
        "def read_webster_dict(path=\"/content/drive/MyDrive/iisc/reverse_dictionary/data/webster_dict.json\"):\n",
        "  with open(path) as f:\n",
        "    webster = json.load(f)\n",
        "  return remove_duplicates([(key.lower(), clean_text(value)) for key,value in webster.items()])\n",
        "\n",
        "def read_edmt_dict(path=\"/content/drive/MyDrive/iisc/reverse_dictionary/data/edmt_dict.json\"):\n",
        "  with open(path) as f:\n",
        "    edmt = json.load(f)\n",
        "  return remove_duplicates([(entry['word'].lower(), clean_text(entry['description'])) for entry in edmt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyptubaYzxyr",
        "outputId": "b9f9078d-0f99-42c3-8365-a2578d30728e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webster has 102217 word-definition pairs.\n",
            "('coloradoite', 'Mercury telluride, an iron-black metallic mineral, found in Colorado.')\n",
            "EDMT has 110474 word-definition pairs.\n",
            "('diaconal', 'Of or pertaining to a deacon.')\n",
            "WordNet has 88440 word-definition pairs.\n",
            "('zone', 'any of the regions of the surface of the Earth loosely divided according to latitude or longitude')\n",
            "Unix has 89930 word-definition pairs.\n",
            "('anaerobically', 'not aerobic')\n",
            "Webster has 64574 word-definition pairs after processing.\n",
            "('sea titling', 'The rock pipit.')\n",
            "EDMT has 56336 word-definition pairs after processing.\n",
            "('circumvection', 'The act of carrying anything around, or the state of being so carried.')\n",
            "Webster has 25307 word-definition pairs after Glove filtering.\n",
            "('ego', 'The conscious and permanent subject of all psychical experiences, whether held to be directly known or the product of reflective thought; -- opposed to non-ego.')\n",
            "EDMT has 28291 word-definition pairs after Glove filtering.\n",
            "('inauguration', 'The act of inuagurating, or inducting into office with solemnity')\n",
            "WordNet has 61027 word-definition pairs after Glove filtering.\n",
            "('separative', '(used of an accent in Hebrew orthography) indicating that the word marked is separated to a greater or lesser degree rhythmically and grammatically from the word that follows it')\n",
            "Unix has 89930 word-definition pairs after Glove filtering.\n",
            "('wore', 'deteriorate through use or stress')\n"
          ]
        }
      ],
      "source": [
        "webster = read_webster_dict()\n",
        "edmt = read_edmt_dict()\n",
        "unix = pickle.load(open('/content/drive/MyDrive/iisc/reverse_dictionary/data/unix-dictionary.pkl', 'rb'))['dictionary']\n",
        "print(\"Webster has {} word-definition pairs.\".format(len(webster)))\n",
        "print(random.choice(webster))\n",
        "print(\"EDMT has {} word-definition pairs.\".format(len(edmt)))\n",
        "print(random.choice(edmt))\n",
        "print(\"WordNet has {} word-definition pairs.\".format(len(wordnet)))\n",
        "print(random.choice(wordnet))\n",
        "print(\"Unix has {} word-definition pairs.\".format(len(unix)))\n",
        "print(random.choice(unix))\n",
        "if process_dictionaries:\n",
        "  webster = process_dictionary(webster, 'webster')\n",
        "  edmt = process_dictionary(edmt, 'edmt')\n",
        "  print(\"Webster has {} word-definition pairs after processing.\".format(len(webster)))\n",
        "  print(random.choice(webster))\n",
        "  print(\"EDMT has {} word-definition pairs after processing.\".format(len(edmt)))\n",
        "  print(random.choice(edmt))\n",
        "if filter_using_glove:\n",
        "  webster = glove_filter(webster)\n",
        "  edmt = glove_filter(edmt)\n",
        "  wordnet = glove_filter(wordnet)\n",
        "  unix = glove_filter(unix)\n",
        "  print(\"Webster has {} word-definition pairs after Glove filtering.\".format(len(webster)))\n",
        "  print(random.choice(webster))\n",
        "  print(\"EDMT has {} word-definition pairs after Glove filtering.\".format(len(edmt)))\n",
        "  print(random.choice(edmt))\n",
        "  print(\"WordNet has {} word-definition pairs after Glove filtering.\".format(len(wordnet)))\n",
        "  print(random.choice(wordnet))\n",
        "  print(\"Unix has {} word-definition pairs after Glove filtering.\".format(len(unix)))\n",
        "  print(random.choice(unix))\n",
        "if dont_use_edmt:\n",
        "  edmt = []\n",
        "if dont_use_webster:\n",
        "  webster = []\n",
        "if dont_use_unix:\n",
        "  unix = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-8o3DaVz12A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ec115e9feb4e4ad895d817dd63ea9ea7",
            "8198c6ec6f5a4c1e8fbc49803b42fdd5",
            "86b0a01814d84dd79ece729f3be4ba7a",
            "bd01fc41ee654cbd88469bae51279e85",
            "2b24c248925f4e0bb19802806437b9e1",
            "a7bdb96af7af4989ad683517bec92534",
            "c3b5bec9849b4671a5a18f5663a70fe0",
            "9409119e0a2f4c5393698391bf9ffa46",
            "77c13258f1864a00b70a00d4b405b28e",
            "5a38096fe0c1452ba0297139109f1d25",
            "f669ac83024d4506a3c67742aee16239",
            "e3c909e7dc2a46ddba3a9a4ad7583b29",
            "37bbfc0d594e4eecbfb1ee52387b37c7",
            "80f2218bf9ca4260ae35b36442201496",
            "101aa3e126c746b5a8cf39caf637d0b4",
            "688548fdcc3f419aa577020bc99b7458",
            "2c0b4b75bc5a405d84ec5a87febec3bc",
            "0b73b1410b61499dbd0f8e4a8f0018a8",
            "b9350201203d4a7c9c16859a72248828",
            "e5630a4024a54efbab927699aecdfa53",
            "7b7bb54ba46941849c5f1762464e1fd4",
            "d5730034ebda49148abd106a980eb53a",
            "24738c1ffb3e47f69ec60f4656d4a728",
            "22671134943a4e1f92222f34d2df4b48",
            "7c2b5c3260554f8bb4437e0792514c51",
            "d50e9dc0c2574afa8defbf0d9e16f1ce",
            "d0c1ca96cdc144d89a27a052b3474224",
            "ef99c829a0034b19873c2fccc432fb45",
            "0e1333ac832f4dada3bb53a133243c33",
            "22879060ca3d46079e74c7b1133d323f",
            "3ec3df68756946e09175dc0976230112",
            "cbc677d12d4d430dbed2788dea54599f",
            "be782d613a9a4e738029ee745e47ceba",
            "28eb1dc45b8349a38b2463524dd0ab47",
            "18a36802bb3f49fc9e49284f54ca0e59",
            "309c4cc747fd4bd19200ad32e06c19d8",
            "51fe4fdcf148433a94dd4ac2b614727c",
            "740ecec725ec46e29cc3ba9104b908c9",
            "0ea3ae89b49b40e88c0888a4d4ed46db",
            "b5a694b224ad4e56b6558ef69aa4205f",
            "3afa31a9acf348a181154356014f6f71",
            "65e709b7ef594ffc9107798dd9791459",
            "114de7084943484daeb3a5e6cd62e2bb",
            "694737a429de4ab3a9951a0e8ae606ee"
          ]
        },
        "outputId": "66decb70-ba1f-4ffd-a2e0-b0c1ee6b9d06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec115e9feb4e4ad895d817dd63ea9ea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3c909e7dc2a46ddba3a9a4ad7583b29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24738c1ffb3e47f69ec60f4656d4a728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28eb1dc45b8349a38b2463524dd0ab47"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7p5WR1J6SNT"
      },
      "outputs": [],
      "source": [
        "def encode_data(data, tokenizer, using_lstm_model=False, max_def_length=128):\n",
        "  \"\"\"\n",
        "  Removes newlines, then encodes the definition of each word in the input. Prunes away those inputs whose encoded length exceeds\n",
        "  max_length. Also returns the encoded gold-truth outputs.\n",
        "  Observation - the encoded word is anywhere from 2 to 9 tokens long. Since a word may correspond to more than one token,\n",
        "  it is hard to enforce a 1-token rule. Hence, we just enforce that the output is at most 10 tokens long.\n",
        "  \"\"\"\n",
        "  num_total = len(data)\n",
        "  encoded_def = []\n",
        "  encoded_def_attn_masks = []\n",
        "  encoded_targets = []\n",
        "  for i in range(num_total):\n",
        "    word = data[i][0]\n",
        "    definition = data[i][1].replace('\\n','')\n",
        "    iids = tokenizer.encode(definition, add_special_tokens=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")[0]\n",
        "    if iids.shape[-1] != 128:\n",
        "      continue\n",
        "    attn_mask = (iids != tokenizer.pad_token_id).int()\n",
        "    if word == '':\n",
        "      target = torch.zeros(100)\n",
        "    else:\n",
        "      target = torch.tensor(glove_vectors[word])\n",
        "    encoded_def.append(iids)\n",
        "    encoded_def_attn_masks.append(attn_mask)\n",
        "    encoded_targets.append(target)\n",
        "  encoded_def = torch.stack(encoded_def)\n",
        "  encoded_def_attn_masks = torch.stack(encoded_def_attn_masks)\n",
        "  encoded_targets = torch.stack(encoded_targets)\n",
        "  return (encoded_def, encoded_def_attn_masks, encoded_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrqGrq1p7XII"
      },
      "outputs": [],
      "source": [
        "combined_dataset = webster + edmt + wordnet + unix\n",
        "encoded_dataset = encode_data(combined_dataset, bert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "hFz2050GC-Xh",
        "outputId": "3b76c1a3-8a2b-494e-d473-ef7959b77de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ce6854c6fdd4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encoded_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_T69eev6jdJ",
        "outputId": "5a4f4de8-48b1-487b-c7da-d248ecbdc6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall, using torch.Size([150957, 128]) examples.\n",
            "Overall, using torch.Size([150957, 128]) examples.\n",
            "Example encoded sentence:\n",
            "tensor([ 101, 3143,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Example encoded target:\n",
            "torch.Size([150957, 100])\n"
          ]
        }
      ],
      "source": [
        "print(\"Overall, using {} examples.\".format(encoded_dataset[0].shape))#input token\n",
        "print(\"Overall, using {} examples.\".format(encoded_dataset[1].shape))#mask\n",
        "print(\"Example encoded target:\\n{}\".format(encoded_dataset[2].shape))#target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtVBc6geBh2-"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(encoded_dataset):\n",
        "  \"\"\"\n",
        "  Splits the dataset into train, validation and test datasets. Currently, 92%, 4.8% and 3.2% of the samples go to the training, validation\n",
        "  and test sets, respectively.\n",
        "  \"\"\"\n",
        "  train_enc_def, val_test_enc_def, train_targets, val_test_targets = train_test_split(encoded_dataset[0], encoded_dataset[2], random_state=199, test_size=0.08)\n",
        "  train_attn_masks, val_test_attn_masks, _, _ = train_test_split(encoded_dataset[1], encoded_dataset[2], random_state=199, test_size=0.08)\n",
        "  val_enc_def, test_enc_def, val_targets, test_targets = train_test_split(val_test_enc_def, val_test_targets, random_state=1700, test_size=0.4)\n",
        "  val_attn_masks, test_attn_masks, _, _ = train_test_split(val_test_attn_masks, val_test_targets, random_state=1700, test_size=0.4)\n",
        "\n",
        "  return {\n",
        "      'train' : (train_enc_def, train_attn_masks, train_targets),\n",
        "      'validation' : (val_enc_def, val_attn_masks, val_targets),\n",
        "      'test' : (test_enc_def, test_attn_masks, test_targets)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rbw1c1_8Ml3",
        "outputId": "72c0d5d4-6973-4cbb-c2ec-d6e4eeea3f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train examples : 138880\n",
            "Number of validation examples : 7246\n",
            "Number of test examples : 4831\n"
          ]
        }
      ],
      "source": [
        "split_dataset = train_val_test_split(encoded_dataset)\n",
        "print(\"Number of train examples : {}\".format(split_dataset['train'][0].shape[0]))\n",
        "print(\"Number of validation examples : {}\".format(split_dataset['validation'][0].shape[0]))\n",
        "print(\"Number of test examples : {}\".format(split_dataset['test'][0].shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0QRY09Jps64"
      },
      "outputs": [],
      "source": [
        "class BertLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  BERT -> LSTM -> Linear\n",
        "  \"\"\"\n",
        "  def __init__(self, out_dim=100, seq_len=128):\n",
        "    super().__init__()\n",
        "    self.out_dim = out_dim\n",
        "    self.seq_len = seq_len\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.hidden_size = self.bert.config.hidden_size\n",
        "    self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size, bidirectional=True)\n",
        "    self.Linear = nn.Linear(self.hidden_size*2, self.out_dim)\n",
        "    self.train_mode = True\n",
        "\n",
        "  def train(self):\n",
        "    self.train_mode = True\n",
        "\n",
        "  def eval(self):\n",
        "    self.train_mode = False\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.bert(input_ids,attention_mask)\n",
        "    encoded_layers, pooled_output = outputs.last_hidden_state, outputs.pooler_output\n",
        "    seq_lens = encoded_layers.shape[0] * [self.seq_len]\n",
        "    encoded_layers = encoded_layers.permute(1, 0, 2)\n",
        "    enc_hiddens, (last_hidden, last_cell) = self.LSTM(nn.utils.rnn.pack_padded_sequence(encoded_layers, seq_lens))\n",
        "    output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
        "    output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    if self.train_mode:\n",
        "      output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    return self.Linear(output_hidden)\n",
        "\n",
        "class BertMultiLSTM(nn.Module):\n",
        "  \"\"\"\n",
        "  BERT -> 4 x (LSTM + Dropout) -> Linear\n",
        "  \"\"\"\n",
        "  def __init__(self, out_dim=100, seq_len=128):\n",
        "    super().__init__()\n",
        "    self.out_dim = out_dim\n",
        "    self.seq_len = seq_len\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.hidden_size = self.bert.config.hidden_size\n",
        "    self.LSTM = nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=4, dropout=0.1, bidirectional=True)\n",
        "    self.Linear = nn.Linear(self.hidden_size*2, self.out_dim)\n",
        "    self.train_mode = True\n",
        "\n",
        "  def train(self):\n",
        "    self.train_mode = True\n",
        "\n",
        "  def eval(self):\n",
        "    self.train_mode = False\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    outputs = self.bert(input_ids,attention_mask)\n",
        "    encoded_layers, pooled_output = outputs.last_hidden_state, outputs.pooler_output\n",
        "    seq_lens = encoded_layers.shape[0] * [self.seq_len]\n",
        "    encoded_layers = encoded_layers.permute(1, 0, 2)\n",
        "    enc_hiddens, (last_hidden, last_cell) = self.LSTM(nn.utils.rnn.pack_padded_sequence(encoded_layers, seq_lens))\n",
        "    output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
        "    if self.train_mode:\n",
        "      output_hidden = nn.functional.dropout(output_hidden,0.2)\n",
        "    return self.Linear(output_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870,
          "referenced_widgets": [
            "1e7a9dd1c4f64ff98fba879a67689ff6",
            "b71efdd28705454d87867368ae87afe4",
            "2483ba95e4ba483baa7b7999988c7dfc",
            "83344df909704a1589f1754e192bd4a0",
            "cc937c13b93243c0974cb1d3ae14cc0e",
            "8581e4ca23f8436d92d352d7c040438e",
            "4a2c4ac2b3584b6db16ec23a848dbad3",
            "39ad53e713a94cc5ad61bc1cdcffb610",
            "035f34730afc49ab9a974a750fb16108",
            "644960de773e46faba44857cdc78bfd1",
            "d1c3f7f1c3ec40dcbb31fb477b016def"
          ]
        },
        "id": "UdTUXKFT8c4c",
        "outputId": "d7e9d00f-c8c8-422a-b3c4-8ca88b2e1fd3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e7a9dd1c4f64ff98fba879a67689ff6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertLSTM(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (LSTM): LSTM(768, 768, bidirectional=True)\n",
            "  (Linear): Linear(in_features=1536, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "if use_multi_layers:\n",
        "  bert_lstm_model = BertMultiLSTM()\n",
        "else:\n",
        "  bert_lstm_model = BertLSTM()\n",
        "print(bert_lstm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ7RFvv69uA7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = TensorDataset(*split_dataset['train'])\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_dataset = TensorDataset(*split_dataset['validation'])\n",
        "validation_sampler = RandomSampler(validation_dataset)\n",
        "validation_dataloader = DataLoader(validation_dataset, sampler=validation_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ifb3GVajaIM",
        "outputId": "c7274094-7187-48fc-e67e-06e56f033e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPUs available, using CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
        "  device = torch.device(\"cuda\")\n",
        "  bert_lstm_model.cuda()\n",
        "else:\n",
        "  print(\"No GPUs available, using CPU\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOQhN8vlkEMb"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(preds_flat == labels_flat) / labels_flat.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv4QTImb-9TH"
      },
      "outputs": [],
      "source": [
        "def get_max_checkpt(checkpt_dir):\n",
        "  max_checkpt = 0\n",
        "  for filename in os.listdir(checkpt_dir):\n",
        "    if re.match(r\"checkpt-([0-9]+).pt\", filename):\n",
        "      checkpt_num = int(filename.split('.')[-2].split('-')[-1])\n",
        "      if checkpt_num > max_checkpt:\n",
        "        max_checkpt = checkpt_num\n",
        "  return max_checkpt\n",
        "\n",
        "def load_latest_checkpt(checkpt_dir=CHECKPT_DIR):\n",
        "  if force_restart_training:\n",
        "    return\n",
        "  mx_checkpt = get_max_checkpt(checkpt_dir)\n",
        "  if mx_checkpt > 0:\n",
        "    checkpt_file = os.path.join(checkpt_dir, \"checkpt-{}.pt\".format(mx_checkpt))\n",
        "    bert_lstm_model.load_state_dict(torch.load(checkpt_file))\n",
        "  return mx_checkpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F_hoOdTipgk"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 5\n",
        "NUM_STEPS = len(train_dataloader) * NUM_TARGET_EPOCHS\n",
        "optimizer = AdamW(bert_lstm_model.parameters(), lr=2e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=NUM_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqzwSy7psqax"
      },
      "outputs": [],
      "source": [
        "def train_bert_lstm():\n",
        "  loss_values = []\n",
        "  start_epoch =load_latest_checkpt()# 0-indexed\n",
        "  scheduler.last_epoch = start_epoch - 1\n",
        "  save = True\n",
        "  bert_lstm_model.train()\n",
        "  for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "    print(\"Using BERT-LSTM model\")\n",
        "    print(\"======== Epoch {} / {} ========\".format(epoch+1, NUM_EPOCHS))\n",
        "    print(\"Training phase\")\n",
        "    epoch_start = time.time()\n",
        "    epoch_loss = 0\n",
        "    bert_lstm_model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      if step % 40 == 0 and step != 0:\n",
        "        elapsed = format_time(time.time() - epoch_start)\n",
        "        print(\"Batch {} of {}. Elapsed {}\".format(step, len(train_dataloader), elapsed))\n",
        "      batch_enc_def = batch[0].to(device)\n",
        "      batch_attn_mask = batch[1].to(device)\n",
        "      batch_targets = batch[2].to(device) # These are the glove vectors\n",
        "      bert_lstm_model.zero_grad()\n",
        "      outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "      # This function takes logits and labels\n",
        "      MSE = nn.MSELoss(reduction='none')\n",
        "      loss = MSE(outputs, batch_targets)\n",
        "      loss = torch.mean(torch.sum(loss, axis=1))\n",
        "      epoch_loss += loss\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(bert_lstm_model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "    avg_train_loss = epoch_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"Average training loss for epoch {} : {}\".format(epoch+1, avg_train_loss))\n",
        "    print(\"Epoch took {}\".format(format_time(time.time()-epoch_start)))\n",
        "\n",
        "    print(\"\\nValidation phase\")\n",
        "    val_start = time.time()\n",
        "    bert_lstm_model.eval()\n",
        "    val_loss, val_accuracy = 0, 0\n",
        "    batch_eval_steps, batch_eval_examples = 0, 0\n",
        "    for batch in validation_dataloader:\n",
        "      batch = tuple(tup.to(device) for tup in batch)\n",
        "      batch_enc_def, batch_attn_mask, batch_targets = batch\n",
        "      with torch.no_grad():\n",
        "        outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "      MSE = nn.MSELoss(reduction='none')\n",
        "      loss = MSE(outputs, batch_targets)\n",
        "      loss = torch.mean(torch.sum(loss, axis=1))\n",
        "      val_loss += loss\n",
        "    avg_val_loss = val_loss / len(validation_dataloader)\n",
        "    print(\"Validation loss: {}\".format(avg_val_loss))\n",
        "    print(\"Validation took {}\".format(format_time(time.time()-val_start)))\n",
        "    if save:\n",
        "      checkpt_path = os.path.join(CHECKPT_DIR, \"checkpt-{}.pt\".format(epoch+1))\n",
        "      torch.save(bert_lstm_model.state_dict(), checkpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "1yHlgdN9_TFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbnDsBzY_T8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549b972b-62e1-4f7b-a9f7-4539ca20ae9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using BERT-LSTM model\n",
            "======== Epoch 1 / 5 ========\n",
            "Training phase\n"
          ]
        }
      ],
      "source": [
        "train_bert_lstm()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bert_lstm_model.eval()"
      ],
      "metadata": {
        "id": "TE0xyAV4H2k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkGTbBj1xi3e"
      },
      "outputs": [],
      "source": [
        "def has_blocked_chars(word):\n",
        "  \"\"\"\n",
        "  Prune away words with spurious characters such as @\n",
        "  \"\"\"\n",
        "  return (word in sample_bad_words) or any(not char.isalpha() for char in word)\n",
        "\n",
        "def get_k_closest_words(vec, k=5, skip_implausible=True):\n",
        "  \"\"\"\n",
        "  Returns top k closest words when comparing - for now only k=1 is supported.\n",
        "  \"\"\"\n",
        "  vec = vec.detach().cpu().numpy().flatten()\n",
        "  closest = [None] * k\n",
        "  distances = [math.inf] * k\n",
        "  for word, wvec in glove_vectors.items():\n",
        "    if skip_implausible and has_blocked_chars(word):\n",
        "      continue\n",
        "    distance = np.linalg.norm(wvec-vec)\n",
        "    ind = 0\n",
        "    while ind < k and distances[ind] < distance:\n",
        "      ind += 1\n",
        "    if ind < k:\n",
        "      closest = closest[:ind] + [word] + closest[ind:-1]\n",
        "      distances = distances[:ind] + [distance] + distances[ind:-1]\n",
        "  return closest\n",
        "\n",
        "def get_closest_word(vec, skip_implausible=True):\n",
        "  \"\"\"\n",
        "  Gets the closest word among the glove words to the given vector\n",
        "  \"\"\"\n",
        "  vec = vec.detach().cpu().numpy().flatten()\n",
        "  closest = None\n",
        "  dmin = math.inf\n",
        "  for word, wvec in glove_vectors.items():\n",
        "    if skip_implausible and has_blocked_chars(word):\n",
        "      continue\n",
        "    distance = np.linalg.norm(wvec-vec)\n",
        "    if distance < dmin:\n",
        "      closest = word\n",
        "      dmin = distance\n",
        "  return closest\n",
        "\n",
        "def is_in_top_1_10_100(word, vec):\n",
        "  \"\"\"\n",
        "  Returns three booleans depicting whether the word is among the top 1, 10, and 100\n",
        "  closest ones respectively in terms of word vector distance to vec.\n",
        "  \"\"\"\n",
        "  words_100 = get_k_closest_words(vec=vec, k=100)\n",
        "  if word not in words_100:\n",
        "    return (0,0,0)\n",
        "  else:\n",
        "    idx = words_100.index(word)\n",
        "    if idx == 0:\n",
        "      return (1,1,1)\n",
        "    elif idx < 10:\n",
        "      return (0,1,1)\n",
        "    else:\n",
        "      return (0,0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psaZMs0gwHH4"
      },
      "outputs": [],
      "source": [
        "test_dataset = TensorDataset(*split_dataset['test'])\n",
        "test_sampler = SequentialSampler(test_dataset)                                  # Use a sequential sampler for testing since we may have to resume it after pausing\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseline(inputs):\n",
        "  gvec = np.zeros(100)\n",
        "  n = 0\n",
        "  for word in inputs.split():\n",
        "    if word in glove_vectors:\n",
        "      gvec += glove_vectors[word]\n",
        "      n += 1\n",
        "  if n > 0:\n",
        "    gvec /= n\n",
        "  return gvec\n",
        "\n",
        "def eval_baseline():\n",
        "  total = 0\n",
        "  n1 = 0\n",
        "  n10 = 0\n",
        "  n100 = 0\n",
        "  for sample in test_dataloader:\n",
        "    test_defs = bert_tokenizer.batch_decode(sequences=sample[0], skip_special_tokens=True)\n",
        "    targets = sample[2]\n",
        "    for i in range(targets.shape[0]):\n",
        "      word = torch.from_numpy(get_baseline(test_defs[i])).to(device)\n",
        "      top1, top10, top100 = is_in_top_1_10_100(targets[i], word)\n",
        "      n1 += top1\n",
        "      n10 += top10\n",
        "      n100 += top100\n",
        "      total += 1\n",
        "      print(total, \"done\")\n",
        "  print(total, n1, n10, n100)"
      ],
      "metadata": {
        "id": "7aaTn6zvM7q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w1Qr6ewXfZu"
      },
      "outputs": [],
      "source": [
        "def print_examples():\n",
        "  batch_0 = next(iter(test_dataloader))\n",
        "  batch_0_enc_def = batch_0[0].to(device)\n",
        "  batch_0_attn_mask = batch_0[1].to(device)\n",
        "  batch_0_targets = batch_0[2].to(device)\n",
        "\n",
        "  outputs = bert_lstm_model(input_ids=batch_0_enc_def, attention_mask=batch_0_attn_mask)\n",
        "  tests_decoded = []\n",
        "  targets_decoded = []\n",
        "  with torch.no_grad():\n",
        "    for i in range(outputs.shape[0]):\n",
        "      tests_decoded.append(get_closest_word(outputs[i].cpu()))\n",
        "      targets_decoded.append(get_closest_word(batch_0_targets[i].cpu()))\n",
        "      test_defs = bert_tokenizer.batch_decode(sequences=batch_0_enc_def, skip_special_tokens=True)\n",
        "  print(\"Some examples:\")\n",
        "  for i in range(len(targets_decoded)):\n",
        "    print(\"Definition: \", test_defs[i])\n",
        "    print(\"Our model's output:\", tests_decoded[i])\n",
        "    print(\"Real word:\", targets_decoded[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTyJJDkvMAJ_"
      },
      "outputs": [],
      "source": [
        "def get_testing_accuracies(dataloader, start=0, end=-1):\n",
        "  total = 0\n",
        "  n1 = 0\n",
        "  n10 = 0\n",
        "  n100 = 0\n",
        "  for batch in dataloader:\n",
        "    if start >= batch[2].shape[0]:\n",
        "      start -= BATCH_SIZE\n",
        "      continue\n",
        "    batch_enc_def = batch[0].to(device)\n",
        "    batch_attn_mask = batch[1].to(device)\n",
        "    batch_targets = batch[2].to(device)\n",
        "    outputs = bert_lstm_model(input_ids=batch_enc_def, attention_mask=batch_attn_mask)\n",
        "    for i in range(start, outputs.shape[0]):\n",
        "      actual = get_closest_word(batch_targets[i].cpu())\n",
        "      top1, top10, top100 = is_in_top_1_10_100(actual, outputs[i])\n",
        "      total += 1\n",
        "      n1 += top1\n",
        "      n10 += top10\n",
        "      n100 += top100\n",
        "      start = 0\n",
        "      if i % 100 == 99:\n",
        "        print(\"{} done.\".format(i+1))\n",
        "      if total == end:\n",
        "        break\n",
        "    if total == end:\n",
        "      break\n",
        "  p1 = 100.0 * n1 / total\n",
        "  p10 = 100.0 * n10 / total\n",
        "  p100 = 100.0 * n100 / total\n",
        "  print(\"Top 1 accuracy  : 100% * {} / {} = {}%\".format(n1, total, p1))\n",
        "  print(\"Top 10 accuracy : 100% * {} / {} = {}%\".format(n10, total, p10))\n",
        "  print(\"Top 100 accuracy: 100% * {} / {} = {}%\".format(n100, total, p100))\n",
        "  return n1, n10, n100, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvS_c5JSYVEz"
      },
      "outputs": [],
      "source": [
        "def get_word_from_single_def(definition, tokenizer, use_bert_lstm=True):\n",
        "  single_word_dset = [[\"\", definition]]\n",
        "  encoded = encode_data(single_word_dset, tokenizer)\n",
        "  defn = encoded[0].to(device)\n",
        "  mask = encoded[1].to(device)\n",
        "  outputs = bert_lstm_model(input_ids=defn, attention_mask=mask)\n",
        "  return [get_closest_word(outputs[0])]\n",
        "\n",
        "def get_k_closest_words_from_single_def(definition, tokenizer, use_bert_lstm=True):\n",
        "  single_word_dset = [[\"\", definition]]\n",
        "  encoded = encode_data(single_word_dset, tokenizer)\n",
        "  defn = encoded[0].to(device)\n",
        "  mask = encoded[1].to(device)\n",
        "  outputs = bert_lstm_model(input_ids=defn, attention_mask=mask)\n",
        "  return get_k_closest_words(outputs[0], k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APhLSyABZvmK",
        "outputId": "d36f5f48-38e8-4d5b-c5b5-5d887117ec99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset Accuracy:\n",
            "Top 1: 48.70627199337611%\n",
            "Top 10: 58.9525978058373%\n",
            "Top 100: 65.61788449596357%\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  with open('/content/gdrive/MyDrive/accuracy.txt') as f:\n",
        "    x = f.readlines()[0].split()\n",
        "    x = [int(i) for i in x]\n",
        "  if (x[0] == len(test_dataset)):\n",
        "    break\n",
        "  n1, n10, n100, total = get_testing_accuracies(test_dataloader, x[0], 64)\n",
        "  x[0] += total\n",
        "  x[1] += n1\n",
        "  x[2] += n10\n",
        "  x[3] += n100\n",
        "  with open('/content/gdrive/MyDrive/accuracy.txt', 'w+') as f:\n",
        "    f.write(\"{} {} {} {}\\n\".format(*x))\n",
        "  print(*x, sep=' ')\n",
        "print(\"Test Dataset Accuracy:\")\n",
        "print(\"Top 1: {}%\".format(100.0*x[1]/x[0]))\n",
        "print(\"Top 10: {}%\".format(100.0*x[2]/x[0]))\n",
        "print(\"Top 100: {}%\".format(100.0*x[3]/x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujftz0GBJKcm",
        "outputId": "d34928b8-d333-41c8-a08e-2032da8f0963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some examples:\n",
            "Definition:  in a mutual or shared manner\n",
            "Our model's output: mutually\n",
            "Real word: mutually\n",
            "Definition:  morally reprehensible\n",
            "Our model's output: pathetic\n",
            "Real word: slimy\n",
            "Definition:  a list of divisions ( chapters or articles ) and the pages on which they start\n",
            "Our model's output: contents\n",
            "Real word: contents\n",
            "Definition:  not working properly\n",
            "Our model's output: defective\n",
            "Real word: bad\n",
            "Definition:  not influenced or affected\n",
            "Our model's output: unswayed\n",
            "Real word: uninfluenced\n",
            "Definition:  cause to sense ; make sensitive\n",
            "Our model's output: sensitize\n",
            "Real word: sensitize\n",
            "Definition:  small fishes found in great schools along coasts of europe ; smaller and rounder than herring\n",
            "Our model's output: pilchard\n",
            "Real word: pilchard\n",
            "Definition:  keep from happening or arising ; make impossible\n",
            "Our model's output: preclude\n",
            "Real word: prevent\n",
            "Definition:  cut or tear along an irregular line so that the parts can later be matched for authentication\n",
            "Our model's output: indent\n",
            "Real word: indented\n",
            "Definition:  anything ( straws or pebbles etc. ) taken or chosen at random\n",
            "Our model's output: draw\n",
            "Real word: draw\n",
            "Definition:  used of skin roughened as a result of cold or exposure\n",
            "Our model's output: chapped\n",
            "Real word: chapped\n",
            "Definition:  a tract of land where logs are accumulated\n",
            "Our model's output: yard\n",
            "Real word: yard\n",
            "Definition:  measuring instrument for measuring the luminous intensity of a source by comparing it ( visually or photoelectrically ) with a standard source\n",
            "Our model's output: photometer\n",
            "Real word: photometer\n",
            "Definition:  put at risk\n",
            "Our model's output: dellcptr\n",
            "Real word: venture\n",
            "Definition:  a human female employed to do housework\n",
            "Our model's output: woman\n",
            "Real word: charwoman\n",
            "Definition:  a deduction allowed to a taxpayer because of his or her status ( having certain dependents or being blind or being over 65 etc. )\n",
            "Our model's output: exemption\n",
            "Real word: exemption\n",
            "Definition:  become affected with smut\n",
            "Our model's output: smut\n",
            "Real word: smut\n",
            "Definition:  a warrant to take someone into custody\n",
            "Our model's output: pickup\n",
            "Real word: pickup\n",
            "Definition:  an assertion that something is true or factual\n",
            "Our model's output: claim\n",
            "Real word: claim\n",
            "Definition:  ( used of soaps or cleaning agents ) having a substance ( an abrasive or filler ) added to increase effectiveness\n",
            "Our model's output: built\n",
            "Real word: built\n",
            "Definition:  an electrical device that sends or receives radio or television signals\n",
            "Our model's output: antennas\n",
            "Real word: antenna\n",
            "Definition:  mold consisting of a box with sand shaped to mold metal\n",
            "Our model's output: sandbox\n",
            "Real word: sandbox\n",
            "Definition:  a quick blow delivered with a whip or whiplike object\n",
            "Our model's output: lash\n",
            "Real word: whip\n",
            "Definition:  a person ( or institution ) to whom legal title to property is entrusted to use for another's benefit\n",
            "Our model's output: trustee\n",
            "Real word: trustee\n",
            "Definition:  ( of verse ) having a metric system based on relative duration of syllables\n",
            "Our model's output: quantitative\n",
            "Real word: quantitative\n",
            "Definition:  calling up a spirit or devil\n",
            "Our model's output: ooooooooooooooooooooooooooooooooooooooo\n",
            "Real word: conjuration\n",
            "Definition:  ( astronomy ) a cluster of stars ( or a small constellation )\n",
            "Our model's output: asterism\n",
            "Real word: asterism\n",
            "Definition:  a kind of sealing material that is used to form a hard coating on a porous surface ( as a coat of paint or varnish used to size a surface )\n",
            "Our model's output: sealant\n",
            "Real word: sealant\n",
            "Definition:  ( of the more skilled contestants ) selectively arranged in the draw for position in a tournament so that they meet each other in later rounds\n",
            "Our model's output: seeded\n",
            "Real word: seeded\n",
            "Definition:  a solemn pledge ( to oneself or to another or to a deity ) to do something or to behave in a certain manner\n",
            "Our model's output: vow\n",
            "Real word: vowed\n",
            "Definition:  an instance of questioning\n",
            "Our model's output: questioning\n",
            "Real word: enquiry\n",
            "Definition:  small tubular solitary freshwater hydrozoan polyp\n",
            "Our model's output: wobbegong\n",
            "Real word: hydra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RisClyMyWVHJ",
        "outputId": "2d51c287-b789-4001-8d1a-31066bb68f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bat\n"
          ]
        }
      ],
      "source": [
        "definition = \"sport which uses bat and ball.\"\n",
        "with torch.no_grad():\n",
        "  print(get_word_from_single_def(definition, bert_tokenizer)[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "definition = \"\"\n",
        "with torch.no_grad():\n",
        "  print(get_k_closest_words_from_single_def(definition, bert_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKUHv2LYN-yB",
        "outputId": "92b2fa2e-f065-45e1-ea7a-3755edc145c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['invocation', 'benediction', 'paean', 'denunciation', 'ooooooooooooooooooooooooooooooooooooooo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GRMITdQdXy39"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec115e9feb4e4ad895d817dd63ea9ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8198c6ec6f5a4c1e8fbc49803b42fdd5",
              "IPY_MODEL_86b0a01814d84dd79ece729f3be4ba7a",
              "IPY_MODEL_bd01fc41ee654cbd88469bae51279e85"
            ],
            "layout": "IPY_MODEL_2b24c248925f4e0bb19802806437b9e1"
          }
        },
        "8198c6ec6f5a4c1e8fbc49803b42fdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7bdb96af7af4989ad683517bec92534",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b5bec9849b4671a5a18f5663a70fe0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "86b0a01814d84dd79ece729f3be4ba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9409119e0a2f4c5393698391bf9ffa46",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77c13258f1864a00b70a00d4b405b28e",
            "value": 28
          }
        },
        "bd01fc41ee654cbd88469bae51279e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a38096fe0c1452ba0297139109f1d25",
            "placeholder": "​",
            "style": "IPY_MODEL_f669ac83024d4506a3c67742aee16239",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.67kB/s]"
          }
        },
        "2b24c248925f4e0bb19802806437b9e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7bdb96af7af4989ad683517bec92534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b5bec9849b4671a5a18f5663a70fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9409119e0a2f4c5393698391bf9ffa46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c13258f1864a00b70a00d4b405b28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a38096fe0c1452ba0297139109f1d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f669ac83024d4506a3c67742aee16239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c909e7dc2a46ddba3a9a4ad7583b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37bbfc0d594e4eecbfb1ee52387b37c7",
              "IPY_MODEL_80f2218bf9ca4260ae35b36442201496",
              "IPY_MODEL_101aa3e126c746b5a8cf39caf637d0b4"
            ],
            "layout": "IPY_MODEL_688548fdcc3f419aa577020bc99b7458"
          }
        },
        "37bbfc0d594e4eecbfb1ee52387b37c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c0b4b75bc5a405d84ec5a87febec3bc",
            "placeholder": "​",
            "style": "IPY_MODEL_0b73b1410b61499dbd0f8e4a8f0018a8",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "80f2218bf9ca4260ae35b36442201496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9350201203d4a7c9c16859a72248828",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5630a4024a54efbab927699aecdfa53",
            "value": 570
          }
        },
        "101aa3e126c746b5a8cf39caf637d0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7bb54ba46941849c5f1762464e1fd4",
            "placeholder": "​",
            "style": "IPY_MODEL_d5730034ebda49148abd106a980eb53a",
            "value": " 570/570 [00:00&lt;00:00, 32.2kB/s]"
          }
        },
        "688548fdcc3f419aa577020bc99b7458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c0b4b75bc5a405d84ec5a87febec3bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b73b1410b61499dbd0f8e4a8f0018a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9350201203d4a7c9c16859a72248828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5630a4024a54efbab927699aecdfa53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b7bb54ba46941849c5f1762464e1fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5730034ebda49148abd106a980eb53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24738c1ffb3e47f69ec60f4656d4a728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22671134943a4e1f92222f34d2df4b48",
              "IPY_MODEL_7c2b5c3260554f8bb4437e0792514c51",
              "IPY_MODEL_d50e9dc0c2574afa8defbf0d9e16f1ce"
            ],
            "layout": "IPY_MODEL_d0c1ca96cdc144d89a27a052b3474224"
          }
        },
        "22671134943a4e1f92222f34d2df4b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef99c829a0034b19873c2fccc432fb45",
            "placeholder": "​",
            "style": "IPY_MODEL_0e1333ac832f4dada3bb53a133243c33",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "7c2b5c3260554f8bb4437e0792514c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22879060ca3d46079e74c7b1133d323f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ec3df68756946e09175dc0976230112",
            "value": 231508
          }
        },
        "d50e9dc0c2574afa8defbf0d9e16f1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc677d12d4d430dbed2788dea54599f",
            "placeholder": "​",
            "style": "IPY_MODEL_be782d613a9a4e738029ee745e47ceba",
            "value": " 232k/232k [00:00&lt;00:00, 3.18MB/s]"
          }
        },
        "d0c1ca96cdc144d89a27a052b3474224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef99c829a0034b19873c2fccc432fb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1333ac832f4dada3bb53a133243c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22879060ca3d46079e74c7b1133d323f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ec3df68756946e09175dc0976230112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbc677d12d4d430dbed2788dea54599f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be782d613a9a4e738029ee745e47ceba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28eb1dc45b8349a38b2463524dd0ab47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18a36802bb3f49fc9e49284f54ca0e59",
              "IPY_MODEL_309c4cc747fd4bd19200ad32e06c19d8",
              "IPY_MODEL_51fe4fdcf148433a94dd4ac2b614727c"
            ],
            "layout": "IPY_MODEL_740ecec725ec46e29cc3ba9104b908c9"
          }
        },
        "18a36802bb3f49fc9e49284f54ca0e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea3ae89b49b40e88c0888a4d4ed46db",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a694b224ad4e56b6558ef69aa4205f",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "309c4cc747fd4bd19200ad32e06c19d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afa31a9acf348a181154356014f6f71",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65e709b7ef594ffc9107798dd9791459",
            "value": 466062
          }
        },
        "51fe4fdcf148433a94dd4ac2b614727c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114de7084943484daeb3a5e6cd62e2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_694737a429de4ab3a9951a0e8ae606ee",
            "value": " 466k/466k [00:00&lt;00:00, 7.33MB/s]"
          }
        },
        "740ecec725ec46e29cc3ba9104b908c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea3ae89b49b40e88c0888a4d4ed46db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a694b224ad4e56b6558ef69aa4205f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3afa31a9acf348a181154356014f6f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e709b7ef594ffc9107798dd9791459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "114de7084943484daeb3a5e6cd62e2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694737a429de4ab3a9951a0e8ae606ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7a9dd1c4f64ff98fba879a67689ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b71efdd28705454d87867368ae87afe4",
              "IPY_MODEL_2483ba95e4ba483baa7b7999988c7dfc",
              "IPY_MODEL_83344df909704a1589f1754e192bd4a0"
            ],
            "layout": "IPY_MODEL_cc937c13b93243c0974cb1d3ae14cc0e"
          }
        },
        "b71efdd28705454d87867368ae87afe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8581e4ca23f8436d92d352d7c040438e",
            "placeholder": "​",
            "style": "IPY_MODEL_4a2c4ac2b3584b6db16ec23a848dbad3",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2483ba95e4ba483baa7b7999988c7dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ad53e713a94cc5ad61bc1cdcffb610",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_035f34730afc49ab9a974a750fb16108",
            "value": 440449768
          }
        },
        "83344df909704a1589f1754e192bd4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644960de773e46faba44857cdc78bfd1",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c3f7f1c3ec40dcbb31fb477b016def",
            "value": " 440M/440M [00:05&lt;00:00, 151MB/s]"
          }
        },
        "cc937c13b93243c0974cb1d3ae14cc0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8581e4ca23f8436d92d352d7c040438e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2c4ac2b3584b6db16ec23a848dbad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ad53e713a94cc5ad61bc1cdcffb610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035f34730afc49ab9a974a750fb16108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "644960de773e46faba44857cdc78bfd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c3f7f1c3ec40dcbb31fb477b016def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}